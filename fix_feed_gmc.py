import json
import re
import os
from urllib.parse import quote
import sys

# Force UTF-8 for output to avoid encoding errors on Windows
if sys.stdout.encoding.lower() != 'utf-8':
    sys.stdout.reconfigure(encoding='utf-8')

# Global cache for descriptions
_DESCRIPTIONS_CACHE = None

def load_descriptions():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙˆØµÙ Ù…Ù† Ù…Ù„Ù descriptions.json ÙƒÙ‚Ø§Ù…ÙˆØ³ (ID -> text)"""
    global _DESCRIPTIONS_CACHE
    if _DESCRIPTIONS_CACHE is not None:
        return _DESCRIPTIONS_CACHE
        
    try:
        with open('descriptions.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
            _DESCRIPTIONS_CACHE = {str(k): v for k, v in data.items()}
            return _DESCRIPTIONS_CACHE
    except Exception as f:
        return {}

def clean_description(title, description):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙˆØµÙ ÙˆØ­Ø°Ù Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…ÙƒØ±Ø± Ù…Ù† Ø¨Ø¯Ø§ÙŠØªÙ‡"""
    if not description:
        return f"{title} - Ù…Ù†ØªØ¬ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø¬ÙˆØ¯Ø© Ù…ØªÙˆÙØ± Ø§Ù„Ø¢Ù† ÙÙŠ Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø¨ØªÙˆØµÙŠÙ„ Ø³Ø±ÙŠØ¹."
    
    clean_title = title.strip()
    if description.startswith(clean_title):
        description = description[len(clean_title):].lstrip(' :-,.ØŒ')
    
    if len(description) < 10:
        return f"Ø§ÙƒØªØ´Ù {title} - Ù…Ù†ØªØ¬ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø¬ÙˆØ¯Ø© Ù…ØªÙˆÙØ± Ø§Ù„Ø¢Ù† ÙÙŠ Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø¨Ø®ØµÙ… Ø­ØµØ±ÙŠ ÙˆØªÙˆØµÙŠÙ„ Ø³Ø±ÙŠØ¹."
        
    # GMC prefers clean text without too many emojis or excessive symbols
    description = re.sub(r'[^\w\s\.\,\!\?\% Ø±.Ø³]', '', description)
    return description[:4900] # GMC limit is 5000

def get_product_description(product_id, title, descriptions=None):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØµÙ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚ ØªÙ…Ø§Ù…Ø§Ù‹ Ù„Ù…Ø§ Ù‡Ùˆ Ù…Ø¹Ø±ÙˆØ¶ ÙÙŠ Ø§Ù„Ù…ØªØ¬Ø±"""
    if descriptions is None:
        descriptions = load_descriptions()
    pid_str = str(product_id)
    raw_desc = descriptions.get(pid_str, "")
    return clean_description(title, raw_desc)

def clean_product_title(title):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ØªØ±ÙˆÙŠØ¬ÙŠØ©"""
    title = re.sub(r'\s+', ' ', title).strip()
    if title.startswith('Ø¹Ø±Ø¶ '):
        title = title[5:]
    return title.strip()

def escape_xml(text):
    """ØªØ±Ù…ÙŠØ² Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ© Ù„Ù€ XML"""
    text = text.replace('&', '&amp;')
    text = text.replace('<', '&lt;')
    text = text.replace('>', '&gt;')
    text = text.replace('"', '&quot;')
    text = text.replace("'", '&apos;')
    return text

def fix_image_url(url):
    """Ø¥ØµÙ„Ø§Ø­ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©"""
    if not url:
        return ""
    
    lower_url = url.lower()
    if lower_url.endswith('.mp4'):
        return url[:-4] + '.jpg'
    elif lower_url.endswith('.webp'):
        return url[:-5] + '.jpg'
    return url

def get_product_category(title):
    """ØªØ­Ø¯ÙŠØ¯ ÙØ¦Ø© Ø§Ù„Ù…Ù†ØªØ¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†"""
    title_lower = title.lower()
    
    if any(word in title_lower for word in ['Ø´Ø¹Ø±', 'Ø´Ø§Ù…Ø¨Ùˆ', 'Ø¨Ù„Ø³Ù…', 'Ø²ÙŠØª', 'Ù…Ø§Ø³Ùƒ', 'ØµØ¨ØºØ©', 'Ø­Ù„Ø§Ù‚Ø©', 'ÙØ±Ø¯', 'ØªÙ…ÙˆÙŠØ¬', 'ØªØµÙÙŠÙ', 'Ù…Ø´Ø·', 'Ù…Ø¨Ø®Ø±Ø©']):
        return 'Health & Beauty > Personal Care > Hair Care', 'Ø§Ù„Ø¹Ù†Ø§ÙŠØ© Ø¨Ø§Ù„Ø´Ø¹Ø±'
    elif any(word in title_lower for word in ['Ø¨Ø´Ø±Ø©', 'ÙƒØ±ÙŠÙ…', 'Ø³ÙŠØ±ÙˆÙ…', 'ÙˆØ§Ù‚ÙŠ', 'Ù…Ø±Ø·Ø¨', 'ØªÙØªÙŠØ­', 'ØµØ§Ø¨ÙˆÙ†', 'ØºØ³ÙˆÙ„', 'Ù…ÙƒÙŠØ§Ø¬', 'Ø±ÙˆØ¬', 'Ø´ÙØ§Ù‡', 'Ù‚Ù†Ø§Ø¹', 'ÙƒÙˆÙ„Ø§Ø¬ÙŠÙ†', 'ÙÙŠÙ„Ø±', 'Ø¨ÙˆØªÙˆÙƒØ³']):
        return 'Health & Beauty > Personal Care > Cosmetics', 'Ø§Ù„Ø¹Ù†Ø§ÙŠØ© Ø¨Ø§Ù„Ø¬Ù…Ø§Ù„'
    elif any(word in title_lower for word in ['Ø¬Ù‡Ø§Ø²', 'Ù…Ø§ÙƒÙŠÙ†Ø©', 'Ø¢Ù„Ø©', 'ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠ', 'Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø´Ø­Ù†', 'Ø´Ø§Ø­Ù†', 'Ø³Ù…Ø§Ø¹Ø©', 'ÙƒØ§Ù…ÙŠØ±Ø§', 'Ø¬ÙˆØ§Ù„', 'ØªØ§Ø¨Ù„Øª', 'Ø³Ø§Ø¹Ø©', 'Ø¶ØºØ·', 'Ù…Ù‚ÙŠØ§Ø³', 'Ù…Ø³Ø§Ø¬', 'ØªØ¯Ù„ÙŠÙƒ']):
        return 'Electronics', 'Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ§Øª'
    elif any(word in title_lower for word in ['ÙÙŠØªØ§Ù…ÙŠÙ†', 'Ù…ÙƒÙ…Ù„', 'ÙƒØ¨Ø³ÙˆÙ„Ø§Øª', 'Ø­Ø¨ÙˆØ¨', 'Ø¹Ù„Ø§Ø¬', 'Ù…Ø´Ø¯', 'Ù…ØµØ­Ø­', 'Ø±ÙƒØ¨Ø©', 'Ø¸Ù‡Ø±', 'ÙƒØ§Ø­Ù„']):
        return 'Health & Beauty > Health Care', 'Ø§Ù„ØµØ­Ø© ÙˆØ§Ù„Ø¹Ø§ÙÙŠØ©'
    elif any(word in title_lower for word in ['Ù…Ù„Ø§Ø¨Ø³', 'Ø´ÙˆØ±Øª', 'Ù‚Ù…ÙŠØµ', 'Ø­Ù‚ÙŠØ¨Ø©', 'Ù†Ø¸Ø§Ø±Ø©', 'Ø­Ø°Ø§Ø¡', 'Ø¬ÙˆØ±Ø¨', 'Ø´Ù…Ø§Øº', 'Ø¨Ø§Ù†Ø¯Ù„', 'Ø¹Ø·Ø±']):
        return 'Apparel & Accessories', 'Ø§Ù„Ø£Ø²ÙŠØ§Ø¡ ÙˆØ§Ù„Ù…ÙˆØ¶Ø©'
    else:
        return 'Home & Garden', 'Ø§Ù„Ù…Ù†Ø²Ù„ ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª'

def create_slug(product):
    """ØªÙˆÙ„ÙŠØ¯ slug ÙØ±ÙŠØ¯ Ù„Ù„Ù…Ù†ØªØ¬"""
    stop_words = ['Ù…Ù†', 'ÙÙŠ', 'Ø¹Ù„Ù‰', 'Ø§Ù„Ù‰', 'Ø¹Ù†', 'Ùˆ', 'Ù…Ø¹', 'ÙŠØ§', 'Ø£ÙŠÙ‡Ø§']
    
    title = product['title']
    for word in stop_words:
        title = title.replace(f' {word} ', ' ')

    slug = re.sub(r'[^\w\s-]', '', title).strip().lower()
    slug = re.sub(r'\s+', '-', slug)
    # Truncate to 100 characters to avoid Windows MAX_PATH issues
    if len(slug) > 100:
        slug = slug[:100].rstrip('-')
    return f"{product['id']}-{slug}"

def fix_product_feed():
    """Ø¥ØµÙ„Ø§Ø­ Ù…Ù„Ù product-feed.xml Ø¨Ø§Ù„ÙƒØ§Ù…Ù„"""
    base_url = "https://sherow1982.github.io/alsooq-alsaudi"
    
    # ÙØ­Øµ ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª
    if not os.path.exists('products.json'):
        print("âŒ products.json not found")
        return
    
    try:
        with open('products.json', 'r', encoding='utf-8') as f:
            products = json.load(f)
    except (json.JSONDecodeError, UnicodeDecodeError) as e:
        print(f"âŒ Error reading products.json: {e}")
        return
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        return
    
    if not products:
        print("âš ï¸ No products found")
        return
    
    descriptions = load_descriptions()
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø© (Ø¹Ø±Ø¨ÙŠ ÙˆØ¥Ù†Ø¬Ù„ÙŠØ²ÙŠ) - Ù‚Ø§Ø¦Ù…Ø© Ø´Ø§Ù…Ù„Ø© Ø¬Ø¯Ø§Ù‹ Ù„ØªØ¬Ù†Ø¨ ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„Ø­Ø³Ø§Ø¨
    PROHIBITED_BRANDS = [
        # Ø§Ù„Ø³Ø§Ø¹Ø§Øª ÙˆØ§Ù„Ù…Ø¬ÙˆÙ‡Ø±Ø§Øª
        'rolex', 'Ø±ÙˆÙ„ÙƒØ³', 'hublot', 'Ù‡ÙˆØ¨Ù„Ùˆ', 'casio', 'ÙƒØ§Ø³ÙŠÙˆ', 'tissot', 'ØªÙŠØ³Ùˆ', 
        'omega', 'Ø£ÙˆÙ…ÙŠØºØ§', 'Ø£ÙˆÙ…ÙŠØ¬Ø§', 'patek philippe', 'Ø¨Ø§ØªÙŠÙƒ ÙÙŠÙ„ÙŠØ¨', 'audemars piguet', 'Ø£ÙˆØ¯ÙŠÙ…Ø§Ø± Ø¨ÙŠØ¬ÙŠÙ‡',
        'cartier', 'ÙƒØ§Ø±ØªÙŠØ±', 'ÙƒØ§Ø±ØªÙŠÙ‡', 'van cleef', 'ÙØ§Ù† ÙƒÙ„ÙŠÙ', 'tiffany', 'ØªÙŠÙØ§Ù†ÙŠ', 'bulgari', 'Ø¨Ù„ØºØ§Ø±ÙŠ',
        'patek', 'Ø¨Ø§ØªÙŠÙƒ', 'audemars', 'Ø£ÙˆØ¯ÙŠÙ…Ø§Ø±', 'vacheron', 'ÙØ§Ø´ÙŠØ±ÙˆÙ†', 'breitling', 'Ø¨Ø±ÙŠØªÙ„ÙŠÙ†Øº',
        # Ø§Ù„Ù…Ù„Ø§Ø¨Ø³ ÙˆØ§Ù„Ø£Ø­Ø°ÙŠØ© ÙˆØ§Ù„Ø­Ù‚Ø§Ø¦Ø¨
        'nike', 'Ù†Ø§ÙŠÙƒ', 'Ù†Ø§ÙŠÙƒÙŠ', 'adidas', 'Ø£Ø¯ÙŠØ¯Ø§Ø³', 'puma', 'Ø¨ÙˆÙ…Ø§', 'gucci', 'Ù‚ÙˆØªØ´ÙŠ',
        'prada', 'Ø¨Ø±Ø§Ø¯Ø§', 'louis vuitton', 'Ù„ÙˆÙŠØ³ ÙÙŠØªÙˆÙ†', 'chanel', 'Ø´Ø§Ù†ÙŠÙ„', 'dior', 'Ø¯ÙŠÙˆØ±',
        'zara', 'Ø²Ø§Ø±Ø§', 'h&m', 'lacoste', 'Ù„Ø§ÙƒÙˆØ³Øª', 'tommy hilfiger', 'ØªÙˆÙ…ÙŠ Ù‡ÙŠÙ„ÙÙŠØºØ±', 'ØªÙˆÙ…ÙŠ',
        'hermes', 'Ù‡ÙŠØ±Ù…ÙŠØ³', 'Ù‡ÙŠØ±Ù…Ø²', 'burberry', 'Ø¨Ø±Ø¨Ø±ÙŠ', 'fendi', 'ÙÙ†Ø¯ÙŠ', 'balenciaga', 'Ø¨Ø§Ù„Ù†Ø³ÙŠØ§ØºØ§',
        'versace', 'ÙØ±Ø²Ø§ØªØ´ÙŠ', 'reebok', 'Ø±ÙŠØ¨ÙˆÙƒ', 'new balance', 'Ù†ÙŠÙˆ Ø¨Ø§Ù„Ø§Ù†Ø³', 'skechers', 'Ø³ÙƒÙŠØªØ´Ø±Ø²',
        'yeezy', 'ÙŠÙŠØ²ÙŠ', 'off-white', 'Ø£ÙˆÙ ÙˆØ§ÙŠØª', 'balmain', 'Ø¨Ø§Ù„Ù…Ø§Ù†', 'valentino', 'ÙØ§Ù„Ù†ØªÙŠÙ†Ùˆ',
        # Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ§Øª ÙˆØ§Ù„Ù‡ÙˆØ§ØªÙ
        'apple', 'Ø£Ø¨Ù„', 'iphone', 'Ø§ÙŠÙÙˆÙ†', 'ipad', 'Ø§ÙŠØ¨Ø§Ø¯', 'samsung', 'Ø³Ø§Ù…Ø³ÙˆÙ†Ø¬', 'sony', 'Ø³ÙˆÙ†ÙŠ',
        'panasonic', 'Ø¨Ø§Ù†Ø§Ø³ÙˆÙ†ÙŠÙƒ', 'huawei', 'Ù‡ÙˆØ§ÙˆÙŠ', 'xiaomi', 'Ø´Ø§ÙˆÙ…ÙŠ', 'hp', 'dell', 'lenovo', 'Ù„ÙŠÙ†ÙˆÙÙˆ',
        'canon', 'ÙƒØ§Ù†ÙˆÙ†', 'nikon', 'Ù†ÙŠÙƒÙˆÙ†', 'lg', 'Ø§Ù„ Ø¬ÙŠ', 'philips', 'ÙÙŠÙ„Ø¨Ø³', 'ÙÙŠÙ„ÙŠØ¨Ø³',
        'dyson', 'Ø¯Ø§ÙŠØ³ÙˆÙ†', 'nintendo', 'Ù†ÙŠÙ†ØªÙ†Ø¯Ùˆ', 'playstation', 'Ø¨Ù„Ø§ÙŠØ³ØªÙŠØ´Ù†', 'xbox', 'Ø§ÙƒØ³ Ø¨ÙˆÙƒØ³',
        # Ø§Ù„Ø¹Ø·ÙˆØ± ÙˆÙ…ÙˆØ§Ø¯ Ø§Ù„ØªØ¬Ù…ÙŠÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©
        'sauvage', 'Ø³ÙˆÙØ§Ø¬', 'bleu de chanel', 'Ø¨Ù„Ùˆ Ø¯ÙŠ Ø´Ø§Ù†ÙŠÙ„', 'creed', 'ÙƒØ±ÙŠØ¯', 
        'tom ford', 'ØªÙˆÙ… ÙÙˆØ±Ø¯', 'mac', 'Ù…Ø§Ùƒ', 'loreal', 'Ù„ÙˆØ±ÙŠØ§Ù„', 'maybelline', 'Ù…ÙŠØ¨ÙŠÙ„ÙŠÙ†',
        'gillette', 'Ø¬ÙŠÙ„ÙŠØª', 'braun', 'Ø¨Ø±Ø§ÙˆÙ†', 'oral-b', 'Ø£ÙˆØ±Ø§Ù„ Ø¨ÙŠ', 'pantene', 'Ø¨Ø§Ù†ØªÙŠÙ†'
    ]
    
    xml = ['<?xml version="1.0" encoding="UTF-8"?>']
    xml.append('<rss xmlns:g="http://base.google.com/ns/1.0" version="2.0">')
    xml.append('  <channel>')
    xml.append('    <title>Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ</title>')
    xml.append(f'    <link>{base_url}/</link>')
    xml.append('    <description>Ø£ÙØ¶Ù„ Ø§Ù„Ø¹Ø±ÙˆØ¶ ÙˆØ§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø¨Ø£Ø³Ø¹Ø§Ø± ØªÙ†Ø§ÙØ³ÙŠØ©</description>')
    
    excluded_count = 0
    for product in products:
        skip_product = False
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹
        clean_title = clean_product_title(product['title'])
        title_lower = clean_title.lower()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø© Ø¨Ø¯Ù‚Ø© (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø­Ø¯ÙˆØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©)
        for brand in PROHIBITED_BRANDS:
            if re.search(r'[a-zA-Z]', brand): # English Brand
                if re.search(r'\b' + re.escape(brand) + r'\b', title_lower):
                    print(f"ğŸš« Excluded brand detected (English): {brand} in {clean_title}")
                    skip_product = True
                    excluded_count += 1
                    break
            else: # Arabic Brand
                if brand in title_lower:
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø§Ø±ÙƒØ© Ù„ÙŠØ³Øª Ø¬Ø²Ø¡Ø§Ù‹ Ù…Ù† ÙƒÙ„Ù…Ø© Ø´Ø§Ø¦Ø¹Ø© (Ù…Ø«Ù„ 'Ù…Ø§ÙƒÙŠÙ†Ø©')
                    # Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø³Ù†Ø¹ØªØ²Ù… Ø£Ù† Ø§Ù„Ù…Ø§Ø±ÙƒØ© ÙƒÙ„Ù…Ø© Ù…Ø³ØªÙ‚Ù„Ø©
                    if re.search(r'(^|\s)' + re.escape(brand) + r'($|\s)', title_lower):
                        print(f"ğŸš« Excluded brand detected (Arabic): {brand} in {clean_title}")
                        skip_product = True
                        excluded_count += 1
                        break
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ù…Ù†ØªØ¬
        if 'not compatible with our policy' in clean_title.lower():
            skip_product = True
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙˆØ±
        image_link = fix_image_url(product['image_link'])
        if not image_link or image_link.endswith('.mp4'):
            skip_product = True
        
        if skip_product:
            continue
        
        # ØªÙˆÙ„ÙŠØ¯ slug
        slug = create_slug({'id': product['id'], 'title': product['title']})
        encoded_slug = quote(slug)
        product_link = f"{base_url}/products/{encoded_slug}.html"
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ÙØ¦Ø© Ù…Ø¹ ØªØ±Ù…ÙŠØ² &
        google_cat, product_type = get_product_category(clean_title)
        google_cat = escape_xml(google_cat)
        
        # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ù…Ø·Ø§Ø¨Ù‚ ØªÙ…Ø§Ù…Ø§Ù‹ Ù„Ù„Ù…ØªØ¬Ø±
        description = get_product_description(product['id'], clean_title, descriptions)
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª
        mpn = f"ALS{product['id']:06d}"
        gtin = ""
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù†ØªØ¬
        xml.append('    <item>')
        xml.append(f'      <g:id>{product["id"]}</g:id>')
        xml.append(f'      <g:title><![CDATA[{clean_title}]]></g:title>')
        xml.append(f'      <g:description><![CDATA[{description}]]></g:description>')
        xml.append(f'      <g:link>{product_link}</g:link>')
        xml.append(f'      <g:image_link>{image_link}</g:image_link>')
        xml.append('      <g:condition>new</g:condition>')
        xml.append('      <g:availability>in stock</g:availability>')
        xml.append(f'      <g:price>{product["price"]}.00 SAR</g:price>')
        xml.append(f'      <g:sale_price>{product["sale_price"]}.00 SAR</g:sale_price>')
        xml.append('      <g:brand>Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ</g:brand>')
        
        # Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø© - Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ø¹Ø§Ù… 2026
        if mpn:
            xml.append(f'      <g:mpn>{mpn}</g:mpn>')
        
        if gtin:
            xml.append(f'      <g:gtin>{gtin}</g:gtin>')
            xml.append('      <g:identifier_exists>yes</g:identifier_exists>')
        else:
            xml.append('      <g:identifier_exists>no</g:identifier_exists>')

        xml.append(f'      <g:google_product_category>{google_cat}</g:google_product_category>')
        xml.append(f'      <g:product_type>{product_type}</g:product_type>')
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø´Ø­Ù† Ø§Ù„Ù…ÙˆØ­Ø¯Ø©
        xml.append('      <g:shipping>')
        xml.append('        <g:country>SA</g:country>')
        xml.append('        <g:service>Standard</g:service>')
        xml.append('        <g:price>0.00 SAR</g:price>')
        xml.append('      </g:shipping>')
        xml.append('    </item>')
        
    xml.append('  </channel>')
    xml.append('</rss>')
    
    with open('product-feed.xml', 'w', encoding='utf-8') as f:
        f.write('\n'.join(xml))
    
    print(f"Done! product-feed.xml generated successfully")
    print(f"Total products in feed: {len(products) - excluded_count}")
    print(f"Total products excluded (brands/policy): {excluded_count}")
    print("Fixed XML encoding issues (& to &amp;)")
    print("Added required fields: mpn")
    print("Cleaned descriptions from promotional text")
    print("Fixed image URLs")
    print("Formatted prices correctly")

if __name__ == "__main__":
    fix_product_feed()
